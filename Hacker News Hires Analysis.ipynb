{
 "metadata": {
  "name": "Hacker News Hires Analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "from IPython.core import display"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Can we scrape HN? https://news.ycombinator.com/item?id=1721105\n",
      "    \n",
      "# A little setup before we get going"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "posts_savefile = 'posts.csv'\n",
      "tdm_savefile = 'posts_tdm.csv'\n",
      "\n",
      "urls = (\n",
      "(2011, 1, 'https://news.ycombinator.com/item?id=2057704'),\n",
      "(2011, 2, 'https://news.ycombinator.com/item?id=2161360'),\n",
      "(2011, 3, 'https://news.ycombinator.com/item?id=2270790'),\n",
      "(2011, 4, 'https://news.ycombinator.com/item?id=2396027'),\n",
      "(2011, 5, 'https://news.ycombinator.com/item?id=2503204'),\n",
      "(2011, 6, 'https://news.ycombinator.com/item?id=2607052'),\n",
      "(2011, 7, 'https://news.ycombinator.com/item?id=2719028'),\n",
      "(2011, 8, 'https://news.ycombinator.com/item?id=2831646'),\n",
      "(2011, 9, 'https://news.ycombinator.com/item?id=2949787'),\n",
      "(2011, 10, 'https://news.ycombinator.com/item?id=3060221'),\n",
      "(2011, 11, 'https://news.ycombinator.com/item?id=3181796'),\n",
      "(2011, 12, 'https://news.ycombinator.com/item?id=3300290'),\n",
      "(2012, 1, 'https://news.ycombinator.com/item?id=3412900'),\n",
      "(2012, 2, 'https://news.ycombinator.com/item?id=3537881'),\n",
      "(2012, 3, 'https://news.ycombinator.com/item?id=3652041'),\n",
      "(2012, 4, 'https://news.ycombinator.com/item?id=3783657'),\n",
      "(2012, 5, 'https://news.ycombinator.com/item?id=3913997'),\n",
      "(2012, 6, 'https://news.ycombinator.com/item?id=4053076'),\n",
      "(2012, 7, 'https://news.ycombinator.com/item?id=4184755'),\n",
      "(2012, 8, 'https://news.ycombinator.com/item?id=4323597'),\n",
      "(2012, 9, 'https://news.ycombinator.com/item?id=4463689'),\n",
      "(2012, 10, 'https://news.ycombinator.com/item?id=4596375'),\n",
      "(2012, 11, 'https://news.ycombinator.com/item?id=4727241'),\n",
      "(2012, 12, 'https://news.ycombinator.com/item?id=4857714'),\n",
      "(2013, 1, 'https://news.ycombinator.com/item?id=4992617'),\n",
      "(2013, 2, 'https://news.ycombinator.com/item?id=5150834'),\n",
      "(2013, 3, 'https://news.ycombinator.com/item?id=5304169'),       \n",
      "(2013, 4, 'https://news.ycombinator.com/item?id=5472746'),\n",
      "(2013, 5, 'https://news.ycombinator.com/item?id=5637663'),\n",
      "(2013, 6, 'https://news.ycombinator.com/item?id=5803764'),\n",
      "(2013, 7, 'https://news.ycombinator.com/item?id=5970187'),\n",
      "(2013, 8, 'https://news.ycombinator.com/item?id=6139927'),\n",
      "(2013, 9, 'https://news.ycombinator.com/item?id=6310234'),\n",
      "(2013, 10, 'https://news.ycombinator.com/item?id=6475879'),\n",
      "(2013, 11, 'https://news.ycombinator.com/item?id=6653437'),\n",
      "(2013, 12, 'https://news.ycombinator.com/item?id=6827554'),\n",
      "(2014, 1, 'https://news.ycombinator.com/item?id=6995020'),\n",
      "(2014, 2, 'https://news.ycombinator.com/item?id=7162197'),\n",
      "(2014, 3, 'https://news.ycombinator.com/item?id=7324236'),       \n",
      "(2014, 4, 'https://news.ycombinator.com/item?id=7507765'),\n",
      "(2014, 5, 'https://news.ycombinator.com/item?id=7679431')\n",
      ")\n",
      "\n",
      "def filename(year, month):\n",
      "    return 'html/hn_%d_%d.html' % (year, month)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# maybe drop urls into a DataFrame to save to CSV?\n",
      "import pandas as pd\n",
      "urlsdf = pd.DataFrame(list(urls), columns=['year', 'month', 'url'])\n",
      "urlsdf.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>year</th>\n",
        "      <th>month</th>\n",
        "      <th>url</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 2011</td>\n",
        "      <td> 1</td>\n",
        "      <td> https://news.ycombinator.com/item?id=2057704</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2011</td>\n",
        "      <td> 2</td>\n",
        "      <td> https://news.ycombinator.com/item?id=2161360</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2011</td>\n",
        "      <td> 3</td>\n",
        "      <td> https://news.ycombinator.com/item?id=2270790</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "   year  month                                           url\n",
        "0  2011      1  https://news.ycombinator.com/item?id=2057704\n",
        "1  2011      2  https://news.ycombinator.com/item?id=2161360\n",
        "2  2011      3  https://news.ycombinator.com/item?id=2270790"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fetching HTML from Hacker News\n",
      "\n",
      "* Try each item at most 3 times if gettting bad responses\n",
      "* Wait a half minute between grabbing each year/month post\n",
      "* Check for 'Next' link at bottom of page, fetch link if there\n",
      "* Append 'next' pages to end of current HTML fetched\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import collections\n",
      "import os.path\n",
      "import requests\n",
      "import time\n",
      "\n",
      "stack = collections.deque(urls)\n",
      "tries = len(stack) * 3 # maximum attempts 3 times of number of URLs\n",
      "\n",
      "while tries > 0:\n",
      "    tries -= 1\n",
      "    current = stack.pop()\n",
      "    year, month, url = current\n",
      "\n",
      "    # local html output file\n",
      "    fname = filename(year, month)\n",
      "    if os.path.isfile(fname):\n",
      "        os.remove(fname)\n",
      "\n",
      "    try:\n",
      "        # get the HN pages for month / year\n",
      "        ym_pages = [url]\n",
      "        while ym_pages:\n",
      "            url = ym_pages.pop()\n",
      "            print \"Fetching URL: %s\" % (url)\n",
      "            r = requests.get(url)\n",
      "\n",
      "            # fail if bad error code\n",
      "            if r.status_code != requests.codes.ok:\n",
      "                raise Exception('Error from server: ' + str(r.status_code))\n",
      "\n",
      "            text = r.text.replace('&', '_') # broken HTML escapes breaking BeautifulSoup, removing\n",
      "            # write out to file in cwd\n",
      "            with open(fname, 'a') as htmlfile:\n",
      "                htmlfile.write(text.encode('utf-8'))\n",
      "                \n",
      "            # check for 'More' link\n",
      "            soup = BeautifulSoup(text)\n",
      "            links = soup.find_all('a', text='More')\n",
      "            if links:\n",
      "                # sometimes foward slash is being html escaped and messed\n",
      "                # up by above & replacment, need to replace again\n",
      "                link_url = 'https://news.ycombinator.com' + links[0]['href'].replace('_#x2F;', '/')\n",
      "                ym_pages.append(link_url)\n",
      "            \n",
      "            # take a break for 30 seconds\n",
      "            time.sleep(30)\n",
      "            \n",
      "    except Exception as e:\n",
      "        print 'error:', e, 'currently on:', current\n",
      "        # stick current URL at the begining of the queue\n",
      "        stack.appendleft(current)        \n",
      "        \n",
      "    # get out when stack is empty\n",
      "    if not stack: break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# HTML parsing function\n",
      "\n",
      "Parsing of the HTML from Hacker News from HTML to _{user, post}_ dicts\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import re\n",
      "\n",
      "def html_to_posts(html):\n",
      "    \"\"\"Parse an html document into posts\"\"\"\n",
      "    posts = []\n",
      "    html = html.replace(\"<br>\", \"<br/>\") # unclosed <br>'s are messing up BeautifulSoup\n",
      "    soup = BeautifulSoup(html)\n",
      "    tables = soup.body.center.table('tr', recursive=False)[2].td('table', recursive=False)\n",
      "    comments_table = tables[1] if len(tables) > 1 else tables[0]\n",
      "    rows = comments_table('tr', recursive=False)\n",
      "        \n",
      "    for row in rows:        \n",
      "        # check if td and table exist\n",
      "        if not row.td or not row.td.table: continue\n",
      "\n",
      "        # check if this is a top level comment\n",
      "        spacer_img = row.td.table.tr.td.img\n",
      "        if not spacer_img['width'] == '0': continue\n",
      "                \n",
      "        comment_tag = row.find_all('span', class_='comment')[0]\n",
      "        comment = comment_tag.get_text(separator=' ')\n",
      "        #print comment[:30]\n",
      "        if comment == '[deleted]' or comment == '[dead]': continue\n",
      "        \n",
      "        head_tag = row('span', class_='comhead')[0]\n",
      "        user = head_tag.a.text\n",
      "\n",
      "        posts.append({'user': user, 'post': comment.encode('utf-8')})\n",
      "        \n",
      "    return posts\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Looping over fetched HTML\n",
      "\n",
      "* Loop over fetched items\n",
      "* Split at _&lt;/html&gt;_ tags because we appended _Next_ pages\n",
      "* Save out to _CSV_ for later use"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# urls = [(2012, 7, 'https://news.ycombinator.com/item?id=4184755')]\n",
      "posts = []\n",
      "\n",
      "for current in urls:\n",
      "    # print current\n",
      "    year, month, url = current\n",
      "    all_html = open(filename(year, month)).read()\n",
      "    \n",
      "    start_html = 0\n",
      "    while start_html < len(all_html):\n",
      "        end_html = all_html.find('</html>', start_html)\n",
      "        html = all_html[start_html:end_html + 7]\n",
      "        start_html = end_html + 7\n",
      "        \n",
      "        ym_posts = html_to_posts(html)\n",
      "        #print \"Found %d posts\" % len(ym_posts)\n",
      "\n",
      "        for post in ym_posts:\n",
      "            post.update({'date': pd.datetime(year, month, 1)})\n",
      "            posts.append(post)\n",
      "\n",
      "\n",
      "postsdf = pd.DataFrame(posts, columns=['date', 'user', 'post'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Save"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "postsdf.to_csv(posts_savefile, index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Read Posts DataFrame saved to CSV\n",
      "\n",
      "* Read in our _CSV_ of posts\n",
      "* check out it's _head_ and _tail_"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "postsdf = pd.read_csv(posts_savefile, parse_dates=[0])\n",
      "postsdf.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>date</th>\n",
        "      <th>user</th>\n",
        "      <th>post</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>2011-01-01 00:00:00</td>\n",
        "      <td>   lkrubner</td>\n",
        "      <td> In New York City there are a lot of jobs. I we...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2011-01-01 00:00:00</td>\n",
        "      <td> jasonfried</td>\n",
        "      <td> 37signals is hiring two Rails programmers:\\n h...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>2011-01-01 00:00:00</td>\n",
        "      <td>    tptacek</td>\n",
        "      <td> Chicago (or remote) Matasano Security LEAD SOF...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "                 date        user  \\\n",
        "0 2011-01-01 00:00:00    lkrubner   \n",
        "1 2011-01-01 00:00:00  jasonfried   \n",
        "2 2011-01-01 00:00:00     tptacek   \n",
        "\n",
        "                                                post  \n",
        "0  In New York City there are a lot of jobs. I we...  \n",
        "1  37signals is hiring two Rails programmers:\\n h...  \n",
        "2  Chicago (or remote) Matasano Security LEAD SOF...  "
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "postsdf.tail(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>date</th>\n",
        "      <th>user</th>\n",
        "      <th>post</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>9938</th>\n",
        "      <td>2014-05-01 00:00:00</td>\n",
        "      <td> jasonlotito</td>\n",
        "      <td> MeetMe - New Hope, PA (near Philadelphia, Penn...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9939</th>\n",
        "      <td>2014-05-01 00:00:00</td>\n",
        "      <td>   ssharpe67</td>\n",
        "      <td> Datalex - Atlanta, GA\\nReady to use your tech ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9940</th>\n",
        "      <td>2014-05-01 00:00:00</td>\n",
        "      <td>    findwork</td>\n",
        "      <td> Disclaimer: Forgive me for posting here. I jus...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "                    date         user  \\\n",
        "9938 2014-05-01 00:00:00  jasonlotito   \n",
        "9939 2014-05-01 00:00:00    ssharpe67   \n",
        "9940 2014-05-01 00:00:00     findwork   \n",
        "\n",
        "                                                   post  \n",
        "9938  MeetMe - New Hope, PA (near Philadelphia, Penn...  \n",
        "9939  Datalex - Atlanta, GA\\nReady to use your tech ...  \n",
        "9940  Disclaimer: Forgive me for posting here. I jus...  "
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Number of posts per month"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add year and month columsn to dataframe\n",
      "postsdf['year'] = [v.year for v in postsdf.date]\n",
      "postsdf['month'] = [v.month for v in postsdf.date]\n",
      "\n",
      "# add count \n",
      "ymdf = pd.DataFrame({'count': postsdf.groupby(['date']).size()})\n",
      "ymdf = ymdf.reset_index()\n",
      "ymdf['year'] = [v.year for v in ymdf.date]\n",
      "ymdf['month'] = [v.month for v in ymdf.date]\n",
      "\n",
      "# display a table of counts per month per year\n",
      "ymdf[['year', 'month', 'count']].pivot(index='year', columns='month', values='count')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>month</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>10</th>\n",
        "      <th>11</th>\n",
        "      <th>12</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>year</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2011</th>\n",
        "      <td>  88</td>\n",
        "      <td> 150</td>\n",
        "      <td>  27</td>\n",
        "      <td> 218</td>\n",
        "      <td> 217</td>\n",
        "      <td> 257</td>\n",
        "      <td> 224</td>\n",
        "      <td> 230</td>\n",
        "      <td> 191</td>\n",
        "      <td> 198</td>\n",
        "      <td> 230</td>\n",
        "      <td> 203</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012</th>\n",
        "      <td> 149</td>\n",
        "      <td> 201</td>\n",
        "      <td> 251</td>\n",
        "      <td> 201</td>\n",
        "      <td> 231</td>\n",
        "      <td> 227</td>\n",
        "      <td> 194</td>\n",
        "      <td> 245</td>\n",
        "      <td> 214</td>\n",
        "      <td> 248</td>\n",
        "      <td> 221</td>\n",
        "      <td> 230</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013</th>\n",
        "      <td> 192</td>\n",
        "      <td> 219</td>\n",
        "      <td> 291</td>\n",
        "      <td> 343</td>\n",
        "      <td> 323</td>\n",
        "      <td> 263</td>\n",
        "      <td> 292</td>\n",
        "      <td> 309</td>\n",
        "      <td> 239</td>\n",
        "      <td> 426</td>\n",
        "      <td> 298</td>\n",
        "      <td> 263</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014</th>\n",
        "      <td> 223</td>\n",
        "      <td> 330</td>\n",
        "      <td> 340</td>\n",
        "      <td> 356</td>\n",
        "      <td> 389</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "month   1    2    3    4    5    6    7    8    9    10   11   12\n",
        "year                                                             \n",
        "2011    88  150   27  218  217  257  224  230  191  198  230  203\n",
        "2012   149  201  251  201  231  227  194  245  214  248  221  230\n",
        "2013   192  219  291  343  323  263  292  309  239  426  298  263\n",
        "2014   223  330  340  356  389  NaN  NaN  NaN  NaN  NaN  NaN  NaN"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get unique years in the DataFrame\n",
      "years = postsdf['year'].unique()\n",
      "\n",
      "# start a wide matplotlib figure\n",
      "fig = plt.figure(figsize=(15, 3))\n",
      "\n",
      "# plot all the data\n",
      "ax = fig.add_subplot(121)\n",
      "ymdf[['date', 'count']].set_index('date').plot(ax=ax)\n",
      "ax.legend(loc=4)\n",
      "ax.set_title(\"Number of Posts Each Month Since January 2011\")\n",
      "\n",
      "# plot data split out by year\n",
      "ax = fig.add_subplot(122)\n",
      "df = ymdf[['count', 'year', 'month']].pivot('month', 'year')\n",
      "# display(df)\n",
      "df.plot(ax=ax)\n",
      "\n",
      "ax.legend(loc=4)\n",
      "ax.set_title(\"Split Out Per Year\")\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Days of the week"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# postsdf['weekday'] =  [d.strftime('%a') for d in postsdf['date']]\n",
      "postsdf['weekday'] = [d.weekday() for d in postsdf['date']]\n",
      "\n",
      "mar_2011 = datetime.date(2011, 3, 1)\n",
      "after_mar_2011 = postsdf[postsdf['date'] > mar_2011]\n",
      "\n",
      "posts_date_day = after_mar_2011[['date', 'weekday']]\n",
      "\n",
      "grouped = posts_date_day.groupby(['date', 'weekday'])\n",
      "# alltextdf = pd.DataFrame({'post_count': grouped.size(), 'alltext': grouped['post'].apply(merge)})\n",
      "# byweekday = pd.DataFrame({'weekday': grouped['weekday']})\n",
      "# len(grouped.groups.keys())\n",
      "a = pd.DataFrame(grouped.size())\n",
      "a = a.reset_index()\n",
      "b = a.groupby('weekday')\n",
      "c = b.mean()\n",
      "#c\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Term Document Matrix\n",
      "\n",
      "* load up some stopwords\n",
      "* read in our posts from CSV"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = open('stopwords').readlines()\n",
      "stopwords = [w.strip() for w in stopwords]\n",
      "\n",
      "postsdf = pd.read_csv(posts_savefile, parse_dates=[0])#[:2500]\n",
      "\n",
      "postsdf.tail(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* _merge_ merges all posts into one _document_\n",
      "* _words\\_in\\_post_ cleans up _document_ splits words and counts them"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "postsdf2 = postsdf.drop('user', axis=1)\n",
      "\n",
      "def merge(v):\n",
      "    return ' '.join(v)\n",
      "\n",
      "def words_in_post(post):\n",
      "\n",
      "    post = re.sub(r'[\\. |, |\\-|/|\\(|\\)|;|\\[|\\]|:|!|\"|?|=|_|0-9]', ' ', post)\n",
      "    words = post.lower().split()\n",
      "    words = [word for word in words if word and word not in stopwords]\n",
      "    \n",
      "    word_counts = {}\n",
      "    \n",
      "    for word in words:\n",
      "        word_counts[word] = word_counts.get(word, 0) + 1\n",
      "        \n",
      "    return word_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* loop over all _documents_ and create a TDM DataFrame\n",
      "* Save it to CSV"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped = postsdf2.groupby(['date'])\n",
      "alltextdf = pd.DataFrame({'post_count': grouped.size(), 'alltext': grouped['post'].apply(merge)})\n",
      "#postsdf['year'] = [v.year for v in postsdf.date]\n",
      "#postsdf['month'] = [v.month for v in postsdf.date]\n",
      "\n",
      "alltextdf = alltextdf.reset_index()\n",
      "\n",
      "# loop over month/years and extract words for each combo\n",
      "tdm_df = None\n",
      "for i in range(len(alltextdf)):\n",
      "    words = words_in_post(alltextdf['alltext'][i])\n",
      "    date = alltextdf['date'][i]\n",
      "    year = date.year\n",
      "    month =date.month\n",
      "    post_count = alltextdf['post_count'][i]\n",
      "    word_count = len(words.keys())\n",
      "\n",
      "    df = pd.DataFrame([(date, year, month, k, words[k], post_count, word_count) for k in words], \n",
      "                        columns=['date', 'year', 'month', 'term', 'count', 'post_count', 'word_count'])\n",
      "    if type(tdm_df) != pd.DataFrame :\n",
      "        tdm_df = df\n",
      "    else:\n",
      "        tdm_df = pd.concat([tdm_df, df])\n",
      "\n",
      "tdm_df['prop'] = 1.0 * tdm_df['count'] / tdm_df['post_count']\n",
      "tdm_df.to_csv(tdm_savefile, index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Which terms are popular each month?\n",
      "\n",
      "* Read in our TDM from CSV"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdm_df = pd.read_csv(tdm_savefile, parse_dates=[0])\n",
      "tdm_df.head(2)\n",
      "#display(tdm_df.tail(2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>date</th>\n",
        "      <th>year</th>\n",
        "      <th>month</th>\n",
        "      <th>term</th>\n",
        "      <th>count</th>\n",
        "      <th>post_count</th>\n",
        "      <th>word_count</th>\n",
        "      <th>prop</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>2011-01-01 00:00:00</td>\n",
        "      <td> 2011</td>\n",
        "      <td> 1</td>\n",
        "      <td> secondly</td>\n",
        "      <td> 1</td>\n",
        "      <td> 88</td>\n",
        "      <td> 1745</td>\n",
        "      <td> 0.011364</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2011-01-01 00:00:00</td>\n",
        "      <td> 2011</td>\n",
        "      <td> 1</td>\n",
        "      <td> sbnation</td>\n",
        "      <td> 2</td>\n",
        "      <td> 88</td>\n",
        "      <td> 1745</td>\n",
        "      <td> 0.022727</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "                 date  year  month      term  count  post_count  word_count      prop\n",
        "0 2011-01-01 00:00:00  2011      1  secondly      1          88        1745  0.011364\n",
        "1 2011-01-01 00:00:00  2011      1  sbnation      2          88        1745  0.022727"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "linecycler = itertools.cycle(['-', '--', ':'])\n",
      "\n",
      "fig = plt.figure(figsize=(15, 8))\n",
      "ax = fig.add_subplot(111)\n",
      "\n",
      "terms = sorted(['java', 'php', 'python', 'rails', 'django', 'hadoop', 'ember', 'angularjs', 'meteor', 'javascript'])\n",
      "\n",
      "# pull out only the terms we care about\n",
      "df = tdm_df[tdm_df.term.isin(terms)][['date', 'term', 'prop']]\n",
      "\n",
      "for p in terms: #df.columns[1:2]:\n",
      "    subdf = df[df['term'] == p][['date', 'prop']]\n",
      "    subdf = subdf.set_index(['date'])\n",
      "    ax.plot(subdf.index, subdf.values, linestyle=next(linecycler), label=p, linewidth=9)\n",
      "\n",
      "plt.legend(loc=2)\n",
      "a = plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}